# 爬虫第一节课

## http

1. 当用户在地址中输入了网址，发送网络请求的过程是什么？

2. **http的请求方式**

   1. **get**	

      > - url中的参数
      > - 优点：使用比较便捷
      > - 缺点：明文，不安全，参数长度有要求

   2. **post**

      > - 比较安全
      > - 数据整体没有限制
      > - 可以上传文件

   3. put（不完全的）

   4. delete（删除一些信息）

3. 发送网络请求

   - 需要带一定数据给服务器，不带也可以

   - 请求头 requestheader

     > - Accept:文本格式
     > - Accecp-Encoding:编码格式
     > - Connecting：长链接，短连接
     > - Cookie：缓存
     > - Host：域名
     > - Referer:标志从哪个网页过来的
     > - User-Agent：浏览器和用户的信息

   - 返回数据response

4. 请求过程

   - ![image-20200116203447930](C:\Users\123\AppData\Roaming\Typora\typora-user-images\image-20200116203447930.png)

## 爬虫

1. 爬虫的价值

   - 买卖数据（高端的价格特别贵）
   - 数据分析：出分析报告
   - 流量
   - 阿里指数，风云指数

2. 合法性：灰色产业

3. 爬虫只能爬取用户能访问到的数据

   > 例子：
   >
   > 爱奇艺视频
   >
   > 1. 普通用户，普通视频
   > 2. vip客户， 可爬vip
   > 3. 普通user，爬取vip（黑客）

4. 爬虫的分类

   1. 通用爬虫

      > - 优先使用搜索引擎
      > - 优点：速度快，开放性
      > - 劣势：目标不明确
      > - 返回内容：基本上%90是用户不需要的

   2. **聚焦爬虫**

      > - 优点： 目标明确，对用户的需求精准，返回的内容很固定

      - 增量式爬虫

        > - 翻页：从第一页到最后一页
		 - Deep 深度爬虫：
        
          > - 静态数据html，css
          > - 动态数据 js,深度加密的js 
          > - 不用遵守robots
	3. **反爬虫**
		1. 干掉用户
		2. 爬虫和反扒作斗争：资源对等，胜利永远是爬虫
5. 工作原理
	1. 确认你抓取的url是哪一个
	2. 使用python代码发送请求获取数据（java Go也可以)
	3. 解析获取到的数据（精确数据）
	   1. 找到新的目标（url），回到第一步（自动化）
	   2. 知道没有新的url
	4. 数据持久化 
	5. 接下来：
	   1. 原生模块：python3：urlib.request
	      1. urlopen
	      2. get:传参
	      3. post
	      4. handle处理器的自定义
	      5. urlErrOr
	   2. 第三方：requests
	   3. 数据解析：xpath，bs4
	   4. 数据存储